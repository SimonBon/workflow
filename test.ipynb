{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('path/to/dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sample import Sample\n",
    "import matplotlib.pyplot as plt\n",
    "from segmentation.segmentation import Segmentation\n",
    "from skimage.segmentation import find_boundaries\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import preprocessing.preprocess as pp\n",
    "import registration.register as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon_g/workflow/Sample.py:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  self.if_imgs = np.array([cv2.cvtColor(cv2.imread(df[x]), cv2.COLOR_BGR2GRAY) for x in [\"if_b\", \"if_g\", \"if_r\"]])\n"
     ]
    }
   ],
   "source": [
    "# Load the sample from the respective directory\n",
    "sample_directory = \"/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_tmp_simon/20211214_18-2600_BM\"\n",
    "save_directory = \"/save/dir\"\n",
    "example = Sample(sample_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 matches.\n",
      "Found 484 matches.\n",
      "Found 1785 matches.\n"
     ]
    }
   ],
   "source": [
    "#fig, ax = plt.subplots(5, len(example.rois), figsize=(15, 10))\n",
    "\n",
    "for i, roi in enumerate(example.rois):\n",
    "\n",
    "    pp_if = pp.preprocess(roi.if_nuc)\n",
    "    pp_imc = pp.preprocess(roi.imc_nuc_upscaled)\n",
    "\n",
    "    #ax[0, i].imshow(roi.if_nuc)\n",
    "    #ax[1, i].imshow(pp_if)\n",
    "    #ax[2, i].imshow(roi.imc_nuc)\n",
    "    #ax[3, i].imshow(pp_imc)\n",
    "\n",
    "    h = reg.find_matches(pp_if, pp_imc)\n",
    "    transformed = reg.transform(pp_if, pp_imc, h)\n",
    "    #ax[4, i].imshow(additive_blend(transformed, pp_imc))\n",
    "    example.rois[i].if_registered = transformed\n",
    "    print(f\"Registered {roi.roi_num}\")\n",
    "    #plt.tight_layout()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Segmentation Class with thre correct resolution\n",
    "Mesmer = Segmentation(\"mesmer\", mpp=0.175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the IF DAPI Image\n",
    "masks = Mesmer(roi.if_nuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the masks\n",
    "rgb_data = cv2.cvtColor(roi.if_nuc, cv2.COLOR_GRAY2RGB)\n",
    "boundaries = np.zeros_like(roi.if_nuc)\n",
    "overlay_data = np.copy(rgb_data)\n",
    "\n",
    "boundary = find_boundaries(masks, connectivity=0, mode='outer')\n",
    "boundaries[boundary > 0] = 1\n",
    "\n",
    "overlay_data[boundaries > 0] = (255,0,0)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
    "plt.imshow(overlay_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier noch schauen mit dem Registration, dass der Output hier nicht 700 x 700 sondern 4096 auf 4096 ist, einfach vor der registrierung das IMC bild upskalieren und dann darafu registrieren aber nicht speichern.\n",
    "\n",
    "\n",
    "#fig, ax = plt.subplots(5, len(example.rois), figsize=(15, 10))\n",
    "\n",
    "for i, roi in enumerate(example.rois):\n",
    "\n",
    "    pp_if = pp.preprocess(roi.if_nuc)\n",
    "    pp_imc = pp.preprocess(roi.imc_nuc_upscaled)\n",
    "\n",
    "    #ax[0, i].imshow(roi.if_nuc)\n",
    "    #ax[1, i].imshow(pp_if)\n",
    "    #ax[2, i].imshow(roi.imc_nuc)\n",
    "    #ax[3, i].imshow(pp_imc)\n",
    "\n",
    "    h = reg.find_matches(pp_if, pp_imc)\n",
    "    transformed = reg.transform(pp_if, pp_imc, h)\n",
    "    #ax[4, i].imshow(additive_blend(transformed, pp_imc))\n",
    "\n",
    "    #plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0fd0c89bd8fde828876ecbe03217e3a3b5c7b3c1983496cb6dba44b884b6040"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
